# -- configuration to be shared between the authentication components
authentication:
  generatePasswords:
    # -- should a password for the database connection of authentication components be generated in the cluster
    enabled: true
    #-- name of the secret to put the generated password into
    secretName: authentication-database-secret

# -- configuration to be shared between the dataplane components
dataplane:
  generatePasswords:
    # -- should a password for the database connection of dataplane components be generated in the cluster
    enabled: true
    #-- name of the secret to put the generated password into
    secretName: data-service-secret

# -- configuration to be shared between the issuance components
issuance:
  generatePasswords:
    # -- should a password for the database connection of issuance components be generated in the cluster
    enabled: true
    #-- name of the secret to put the generated password into
    secretName: issuance-secret

# -- configuration for the mysql to be deployed as part of the connector, see https://github.com/bitnami/charts/tree/main/bitnami/mysql for all options
mysql:
  # -- should it be enabled? set to false if one outside the chart is used.
  enabled: true
  # -- allows to set a fixed name for the services
  fullnameOverride: authentication-mysql
  # -- configure authentication to mysql
  auth:
    # -- name of the secret to take the passowrds from
    existingSecret: authentication-database-secret
  # -- scripts to be executed on db startup
  initdbScripts:
    create.sql: |
      CREATE DATABASE tildb;
      CREATE DATABASE ccsdb;

# -- configuration for the trusted-issuers-list to be deployed as part of the connector, see https://github.com/FIWARE/helm-charts/tree/main/charts/trusted-issuers-list for all options
trusted-issuers-list:
  # -- should it be enabled? set to false if one outside the chart is used.
  enabled: true
  # -- allows to set a fixed name for the services
  fullnameOverride: trusted-issuers-list
  # -- connection to the database
  database:
    # -- should persistence be used?
    persistence: true
    # -- name of the db user
    username: root
    # -- configuration for the existing secret to get the passwords from
    existingSecret:
      enabled: true
      name: authentication-database-secret
      key: mysql-root-password
    # -- host of the database
    host: authentication-mysql
    # -- name of the schema inside the db
    name: tildb

# -- configuration for the vcverifier to be deployed as part of the connector, see https://github.com/FIWARE/helm-charts/tree/main/charts/vcverifier for all options
vcverifier:
  # -- should it be enabled? set to false if one outside the chart is used.
  enabled: true
  # -- allows to set a fixed name for the services
  fullnameOverride: verifier
  # -- configuration for the m2m flow, in case the tir is requiring authentication
  m2m:
    # -- we do not need authentication here
    authEnabled: false

# -- configuration for the credentials-config-service to be deployed as part of the connector, see https://github.com/FIWARE/helm-charts/tree/main/charts/credentials-config-service for all options
credentials-config-service:
  # -- should it be enabled? set to false if one outside the chart is used.
  enabled: true
  # -- allows to set a fixed name for the services
  fullnameOverride: credentials-config-service
  # -- connection to the database
  database:
    # -- should persistence be used?
    persistence: true
    # -- name of the db user
    username: root
    # -- configuration for the existing secret to get the passwords from
    existingSecret:
      enabled: true
      name: authentication-database-secret
      key: mysql-root-password
    # -- host of the database
    host: authentication-mysql
    # -- name of the schema inside the db
    name: ccsdb

# -- configuration for the postgresql to be deployed as part of the connector, see https://github.com/bitnami/charts/tree/main/bitnami/postgresql for all options
postgresql:
  # -- should it be enabled? set to false if one outside the chart is used.
  enabled: true
  # -- allows to set a fixed name for the services
  fullnameOverride: postgresql
  generatePasswords:
    # -- should a password for the database be generated in the cluster
    enabled: true
    # -- name of the secret to store the password in
    secretName: database-secret
  # -- configure authentication to mysql
  auth:
    # -- name of the secret to take the passowrds from
    existingSecret: database-secret
    # -- key of the secrets inside the secret
    secretKeys:
      adminPasswordKey: postgres-admin-password
      userPasswordKey: postgres-user-password
  # -- configuration for the primary of the db
  primary:
    # -- scripts to be run on intialization
    initdb:
      scripts:
        create.sh: |
          psql postgresql://postgres:${POSTGRES_PASSWORD}@localhost:5432 -c "CREATE DATABASE pap;"
          psql postgresql://postgres:${POSTGRES_PASSWORD}@localhost:5432 -c "CREATE DATABASE keycloak;"

# -- configuration for the odrl-pap to be deployed as part of the connector, see https://github.com/FIWARE/helm-charts/tree/main/charts/odrl-pap for all options
odrl-pap:
  # -- should it be enabled? set to false if one outside the chart is used.
  enabled: true
  # -- allows to set a fixed name for the services
  fullnameOverride: odrl-pap
  # -- configuration about the image to be used
  deployment:
    image:
      repository: quay.io/fiware/odrl-pap
      tag: 0.1.0
      pullPolicy: Always
  # -- connection to the database
  database:
    # -- url to connect the db at
    url: jdbc:postgresql://postgresql:5432/pap
    # -- username to access the db
    username: postgres
    # -- secret to take the password from
    existingSecret:
      enabled: true
      name: database-secret
      key: postgres-admin-password

# -- configuration for the open-policy-agent to be deployed as part of the connector, as a sidecar to apisix
opa:
  # -- should an opa sidecar be deployed to apisix
  enabled: true
  # -- address of the pap to get the policies from
  resourceUrl: http://odrl-pap:8080/bundles/service/v1
  # -- port to make opa available at
  port: 8181
  # -- pull delays for the policies bundle
  policies:
    minDelay: 2
    maxDelay: 4
  # -- pull delays for the methods bundle
  methods:
    minDelay: 1
    maxDelay: 3
  # -- pull delays for the data bundle
  data:
    minDelay: 1
    maxDelay: 15

# -- configuration for apisix to be deployed as part of the connector, see https://github.com/bitnami/charts/tree/main/bitnami/apisix for all options
apisix:
  # -- should it be enabled? set to false if one outside the chart is used.
  enabled: true
  # -- configuration in regard to the apisix control plane
  controlPlane:
    # -- resources config to be set
    resourcesPreset: micro
    # -- should it be enabled
    enabled: true
  # -- configuration in regard to the apisix ingressController
  ingressController:
    # -- should it be enabled
    enabled: false
  # -- configuration in regard to the apisix etcd
  etcd:
    # -- should it be enabled
    enabled: true
    # -- persistence configuration of etcd
    persistence:
      # -- should it be enabled
      enabled: false
  # -- configuration in regard to the apisix dataplane
  dataPlane:
    # -- resources config to be set
    resourcesPreset: micro
    # -- configuration for extra configmaps to be deployed
    extraConfig:
      deployment:
        # -- allows to configure apisix through a yaml file
        role_data_plane:
          config_provider: yaml
    # -- extra volumes
    # we need `routes` to declaratively configure the routes
    # and the config for the opa sidecar
    extraVolumes:
      - name: routes
        configMap:
          name: apisix-routes
      - name: opa-config
        configMap:
          name: opa-config
    # -- extra volumes to be mounted
    extraVolumeMounts:
      - name: routes
        mountPath: /usr/local/apisix/conf/apisix.yaml
        subPath: apisix.yaml
    # -- sidecars to be deployed for apisix
    sidecars:
      # -- we want to deploy the open-policy-agent as a pep
      - name: open-policy-agent
        image: openpolicyagent/opa:0.64.1
        imagePullPolicy: IfNotPresent
        ports:
          - name: http
            containerPort: 8181
            protocol: TCP
        # opa should be started to listen at 8181 and get its config from the mounted config yaml
        args:
          - "run"
          - "--ignore=.*"  # exclude hidden dirs created by Kubernetes
          - "--server"
          - "-l"
          - "debug"
          - "-c"
          - "/config/opa.yaml"
          - "--addr"
          - "0.0.0.0:8181"
        volumeMounts:
          - name: opa-config
            mountPath: /config
  # -- configuration of a catchAll-route(e.g. /*)
  catchAllRoute:
    # -- should it be enabled
    enabled: true
    # -- configuration to connect the upstream broker
    upstream:
      url: http://my-broker:8000
    # -- configuration to verify the jwt, coming from the verifier
    oidc:
      clientId: mySecuredService
      discoveryEndpoint: http://verifier:3000/services/mySecuredService/.well-known/openid-configuration

  # -- configuration of routes for apisix
  routes:
#    - uri: /myRoute
#      upstream:
#        nodes:
#            http://my-upstream-service:8080: 1
#        type: roundrobin
#      plugins:
#        openid-connect:
#          client_id: test-id
#          client_secret: the-secret
#          bearer_only: true
#          use_jwks: true
#          discovery: http://the-service/.well-known/openid-configuration
#        opa:
#          host: "http://localhost:8181"
#          policy: policy/main/allow

# -- configuration for the postgresql to be deployed as part of the connector, see https://github.com/bitnami/charts/tree/main/bitnami/postgresql for all options
postgis:
  # -- should it be enabled? set to false if one outside the chart is used.
  enabled: true
  # -- overrides the generated name, provides stable service names - this should be avoided if multiple instances are available in the same namespace
  fullnameOverride: data-service-postgis
  # -- overrides the generated name, provides stable service names - this should be avoided if multiple instances are available in the same namespace
  nameOverride: data-service-postgis
  ## auth configuration for the database
  auth:
    existingSecret: data-service-secret
    secretKeys:
      adminPasswordKey: postgres-admin-password
      userPasswordKey: postgres-user-password
  ## configuration of the postgres primary replicas
  primary:
    ## provide db initialization
    initdb:
      ## provide scripts for initialization
      scripts:
        # -- enable the postgis extension and create the database as expected by scorpio
        enable.sh: |
          psql postgresql://postgres:${POSTGRES_PASSWORD}@localhost:5432 -c "CREATE EXTENSION postgis;"
          psql postgresql://postgres:${POSTGRES_PASSWORD}@localhost:5432 -c "CREATE DATABASE ngb;"

## configuration of the context-broker - see https://github.com/FIWARE/helm-charts/tree/main/charts/scorpio-broker-aaio for details
scorpio:
  fullnameOverride: data-service-scorpio
  # -- should scorpio be enabled
  enabled: true
  ## configuration of the image to be used
  image:
    # -- repository to be used - resource friendly all-in-one-runner without kafka
    repository: scorpiobroker/all-in-one-runner
    # -- tag of the image to be used - latest java image without kafka
    tag: java-4.1.11
  ## configuration of the database to be used by broker
  db:
    # -- host of the db
    dbhost: data-service-postgis
    # -- username to be used
    user: postgres
    existingSecret:
      enabled: true
      name: data-service-secret
      key: postgres-admin-password
  ## configuration of the readiness probe
  readinessProbe:
    # -- path to be used for the readiness probe, older versions used /actuator/health
    path: /q/health
  ## configuration of the liveness probe
  livenessProbe:
    # -- path to be used for the readiness probe, older versions used /actuator/health
    path: /q/health
  ## configuration to be used for the service offered by scorpio
  service:
    # -- ClusterIP is the recommended type for most clusters
    type: ClusterIP
  # -- configuration to register the dataplane at the credentials-config-service
  ccs:
    # -- endpoint of the ccs to regsiter at
    endpoint: http://credentials-config-service:8080
    # -- configmap to get the registration information from
    configMap: scorpio-registration
    # -- service id of the data-service to be used
    id: data-service
    # -- default scope to be created for the data plane
    defaultOidcScope:
      # -- name of the scope
      name: default
      # -- name of the default credential to be configured
      credentialType: VerifiableCredential
      # -- needs to be updated for the concrete dataspace
      trustedParticipantsLists: http://tir.trust-anchor.org
      trustedIssuersLists: http://trusted-issuers-list:8080
  # -- additional init containers to be used for the dataplane
  initContainers:
    # -- curl container to register at the credentials config service
    - name: register-credential-config
      image: quay.io/curl/curl:8.1.2
      command: [ "/bin/sh", "-c", "/bin/init.sh" ]
      volumeMounts:
        - name: scorpio-registration
          mountPath: /bin/init.sh
          subPath: init.sh
  # -- additonal volumes to be mounted for the dataplane
  additionalVolumes:
    - name: scorpio-registration
      configMap:
        name: scorpio-registration
        defaultMode: 0755

## configuration of the keycloak - see https://github.com/bitnami/charts/tree/main/bitnami/keycloak for details
keycloak:
  # -- should it be enabled? set to false if one outside the chart is used.
  enabled: true
  # -- disable the security context, required by the current quarkus container, will be solved in the future chart versions of keycloak
  containerSecurityContext:
    enabled: false
  # -- keycloak image to be used - set to preview version of 25.0.0, since no other is available yet
  image:
    registry: quay.io
    # until 25 is released, we have to use a snapshot version
    repository: wi_stefan/keycloak
    tag: 25.0.0-PRE
    pullPolicy: Always
  command:
    - /bin/bash
  # -- we need the did of the participant here. when its generated with the did-helper, we have to get it first and replace inside the realm.json through env-vars
  args:
    - -ec
    - |
      #!/bin/sh
      export $(cat /did-material/did.env)
      /opt/keycloak/bin/kc.sh start --features oid4vc-vci --import-realm
  service:
    ports:
      http: 8080
  # -- authentication config for keycloak
  auth:
    existingSecret: issuance-secret
    passwordSecretKey: keycloak-admin
    adminUser: keycloak-admin
  # -- should the db be deployed as part of the keycloak chart
  postgresql:
    enabled: false
  # -- host of the external db to be used
  externalDatabase:
    host: postgresql

  # -- the default init container is deactivated, since it conflicts with the non-bitnami image
  enableDefaultInitContainers: false

  # -- extra volumes to be mounted
  extraVolumeMounts:
    - name: empty-dir
      mountPath: /opt/keycloak/lib/quarkus
      subPath: app-quarkus-dir
    - name: qtm-temp
      mountPath: /qtm-tmp
    - name: did-material
      mountPath: /did-material
    - name: did-material
      mountPath: "/etc/env"
      readOnly: true
    - name: realms
      mountPath: /opt/keycloak/data/import

  extraVolumes:
    - name: did-material
      emptyDir: { }
    - name: qtm-temp
      emptyDir: { }
    - name: realms
      configMap:
        name: test-realm-realm

  # -- extra env vars to be set. we require them at the moment, since some of the chart config mechanisms only work with the bitnami-image
  extraEnvVars:
    # indicates ssl is terminated at the edge
    - name: KC_PROXY
      value: "edge"
    # point the transaction store to the (writeable!) empty volume
    - name: QUARKUS_TRANSACTION_MANAGER_OBJECT_STORE_DIRECTORY
      value: /qtm-tmp
    # config for the db connection
    - name: KC_DB_URL_HOST
      value: postgresql
    - name: KC_DB_URL_DATABASE
      value: keycloak
    - name: KC_DB_USERNAME
      value: postgres
    - name: KC_DB_PASSWORD
      valueFrom:
        secretKeyRef:
          name: database-secret
          key: postgres-admin-password
    # password for reading the key store connected to the did
    - name: STORE_PASS
      valueFrom:
        secretKeyRef:
          name: issuance-secret
          key: store-pass
    # keycloak admin password
    - name: KC_ADMIN_PASSWORD
      valueFrom:
        secretKeyRef:
          name: issuance-secret
          key: keycloak-admin

  # -- init containers to be run with keycloak
  initContainers:
    # workaround required by the current quarkus distribution, to make keycloak working
    - name: read-only-workaround
      image: quay.io/wi_stefan/keycloak:25.0.0-PRE
      command:
        - /bin/bash
      args:
        - -ec
        - |
          #!/bin/bash
          cp -r /opt/keycloak/lib/quarkus/* /quarkus
      volumeMounts:
        - name: empty-dir
          mountPath: /quarkus
          subPath: app-quarkus-dir

    # retrieve all did material required for the realm and store it to a shared folder
    - name: get-did
      image: ubuntu
      command:
        - /bin/bash
      args:
        - -ec
        - |
          #!/bin/bash
          apt-get -y update; apt-get -y install wget
          cd /did-material
          wget http://did-helper:3000/did-material/cert.pfx
          wget http://did-helper:3000/did-material/did.env
      volumeMounts:
        - name: did-material
          mountPath: /did-material

    # register the issuer at the trusted issuers registry - will only work if that one is publicly accessible
    - name: register-at-tir
      image: ubuntu
      command:
        - /bin/bash
      args:
        - -ec
        - |
          #!/bin/bash
          source /did-material/did.env
          apt-get -y update; apt-get -y install curl
          curl -X 'POST' 'http://tir.trust-anchor.svc.cluster.local:8080/issuer' -H 'Content-Type: application/json' -d "{\"did\": \"${DID}\", \"credentials\": []}"
      volumeMounts:
        - name: did-material
          mountPath: /did-material

  # -- configuration of the realm to be imported
  realm:
    # -- should the realm be imported
    import: true
    # -- name of the realm
    name: test-realm
    # -- frontend url to be used for the realm
    frontendURL: http://localhost:8080
    # -- client roles to be imported - be aware the env vars can be used and will be replaced
    clientRoles: |
      "${DID}": [
        {
          "name": "ADMIN",
          "description": "Is allowed to do everything",
          "clientRole": true
        }
      ]
    # -- users to be imported - be aware the env vars can be used and will be replaced
    users: |
      {
        "username": "admin-user",
        "enabled": true,
        "email": "admin@provider.org",
        "firstName": "Test",
        "lastName": "Admin",
        "credentials": [
          {
            "type": "password",
            "value": "test"
          }
        ],
        "clientRoles": {
          "${DID}": [
            "ADMIN"
          ],
          "account": [
            "view-profile",
            "manage-account"
          ]
        },
        "groups": [
        ]
      }
    # -- clients to be imported - be aware the env vars can be used and will be replaced
    clients: |
      {
        "clientId": "${DID}",
        "enabled": true,
        "description": "Client to manage itself",
        "surrogateAuthRequired": false,
        "alwaysDisplayInConsole": false,
        "clientAuthenticatorType": "client-secret",
        "defaultRoles": [],
        "redirectUris": [],
        "webOrigins": [],
        "notBefore": 0,
        "bearerOnly": false,
        "consentRequired": false,
        "standardFlowEnabled": true,
        "implicitFlowEnabled": false,
        "directAccessGrantsEnabled": false,
        "serviceAccountsEnabled": false,
        "publicClient": false,
        "frontchannelLogout": false,
        "protocol": "oid4vc",
        "attributes": {
          "client.secret.creation.time": "1675260539",
          "vc.natural-person.format": "jwt_vc",
          "vc.natural-person.scope": "NaturalPersonCredential",
          "vc.verifiable-credential.format": "jwt_vc",
          "vc.verifiable-credential.scope": "VerifiableCredential"
        },
        "protocolMappers": [
          {
            "name": "target-role-mapper",
            "protocol": "oid4vc",
            "protocolMapper": "oid4vc-target-role-mapper",
            "config": {
              "subjectProperty": "roles",
              "clientId": "${DID}",
              "supportedCredentialTypes": "NaturalPersonCredential"
            }
          },
          {
            "name": "target-vc-role-mapper",
            "protocol": "oid4vc",
            "protocolMapper": "oid4vc-target-role-mapper",
            "config": {
              "subjectProperty": "roles",
              "clientId": "${DID}",
              "supportedCredentialTypes": "VerifiableCredential"
            }
          },
          {
            "name": "context-mapper",
            "protocol": "oid4vc",
            "protocolMapper": "oid4vc-context-mapper",
            "config": {
              "context": "https://www.w3.org/2018/credentials/v1",
              "supportedCredentialTypes": "VerifiableCredential,NaturalPersonCredential"
            }
          },
          {
            "name": "email-mapper",
            "protocol": "oid4vc",
            "protocolMapper": "oid4vc-user-attribute-mapper",
            "config": {
              "subjectProperty": "email",
              "userAttribute": "email",
              "supportedCredentialTypes": "NaturalPersonCredential"
            }
          }
        ],
        "authenticationFlowBindingOverrides": {},
        "fullScopeAllowed": true,
        "nodeReRegistrationTimeout": -1,
        "defaultClientScopes": [],
        "optionalClientScopes": []
      }

# -- configuration for the did-helper, should only be used for demonstrational deployments, see https://github.com/wistefan/did-helper
did:
  enabled: false

# -- configuration for registering a participant at the til, will most probably only be used in demonstrational enviornments
registration:
  enabled: false

# -- configuration for the .well-known/data-space-configuration endpoint document
dataSpaceConfig:
  enabled: false

  # -- Kubernetes Service type
  serviceType: ClusterIP

  # -- Kubernetes Service port
  port: 3002

  # -- Supported data models by the service (array of links to JSON schemas)
  supportedModels: []

  # -- Supported protocols (e.g.: http,https)
  supportedProtocols: []

  # -- Supported authentication protocols (e.g.: oid4vp)
  authenticationProtocols: []
